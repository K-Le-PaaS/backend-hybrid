#!/usr/bin/env python3
"""
ê³ ê¸‰ NLP ê¸°ëŠ¥ ê°„ë‹¨ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê°œë°œ ì¤‘ ë¹ ë¥¸ ê²€ì¦ì„ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import sys
import os
import json
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.llm.advanced_nlp_service import AdvancedNLPService
from app.llm.multi_model_processor import MultiModelProcessor, DEFAULT_CONFIG
from app.llm.context_manager import ContextManager
from app.llm.smart_command_interpreter import SmartCommandInterpreter
from app.llm.learning_processor import LearningProcessor, LearningFeedback
from datetime import datetime


async def test_basic_functionality():
    """ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("=== ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    # ì„¤ì •
    config = {
        "gemini": {
            "enabled": True,
            "base_url": "https://generativelanguage.googleapis.com",
            "api_key": "test-key"  # ì‹¤ì œ í‚¤ê°€ í•„ìš”í•¨
        },
        "claude": {"enabled": False},
        "gpt4": {"enabled": False}
    }
    
    # ì»¨í…ìŠ¤íŠ¸
    context = {
        "project_name": "test-project",
        "current_deployments": [
            {"name": "web-app", "environment": "staging", "replicas": 2},
            {"name": "api-service", "environment": "production", "replicas": 3}
        ]
    }
    
    try:
        # 1. ì§€ëŠ¥ì  ëª…ë ¹ í•´ì„ í…ŒìŠ¤íŠ¸
        print("\n1. ì§€ëŠ¥ì  ëª…ë ¹ í•´ì„ í…ŒìŠ¤íŠ¸")
        interpreter = SmartCommandInterpreter()
        
        test_commands = [
            "ì•± ë°°í¬í•´ì¤˜",
            "web-appì„ stagingì— 3ê°œë¡œ ë°°í¬í•´ì¤˜",
            "ìŠ¤ì¼€ì¼ë§",
            "ìƒíƒœ í™•ì¸"
        ]
        
        for command in test_commands:
            print(f"\nëª…ë ¹: {command}")
            result = await interpreter.interpret_command(command, context)
            print(f"  í•´ì„: {result.interpreted_command}")
            print(f"  ì‹ ë¢°ë„: {result.confidence:.2f}")
            print(f"  ëª¨í˜¸í•¨: {len(result.ambiguities)}ê°œ")
            print(f"  ì œì•ˆ: {len(result.suggestions)}ê°œ")
        
        # 2. ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì í…ŒìŠ¤íŠ¸
        print("\n2. ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì í…ŒìŠ¤íŠ¸")
        context_manager = ContextManager("redis://localhost:6379")
        context_manager.redis_client = None  # ë©”ëª¨ë¦¬ ëª¨ë“œ
        context_manager._memory_store = {}
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        built_context = await context_manager.build_context_for_command(
            "test-user-123", "test-project"
        )
        print(f"  êµ¬ì„±ëœ ì»¨í…ìŠ¤íŠ¸: {built_context}")
        
        # 3. í•™ìŠµ í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸
        print("\n3. í•™ìŠµ í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸")
        learning_processor = LearningProcessor("redis://localhost:6379")
        learning_processor.redis_client = None  # ë©”ëª¨ë¦¬ ëª¨ë“œ
        learning_processor._memory_store = {}
        
        # í”¼ë“œë°± ìƒì„±
        feedback = LearningFeedback(
            user_id="test-user-123",
            command="ì•± ë°°í¬í•´ì¤˜",
            original_interpretation={
                "action": "deploy",
                "target": "unknown",
                "confidence": 0.6
            },
            user_correction={
                "action": "deploy",
                "target": "my-web-app",
                "environment": "staging"
            },
            feedback_type="correction",
            timestamp=datetime.now(),
            success=True,
            context={"project_name": "test-project"}
        )
        
        await learning_processor.record_feedback(feedback)
        print("  í”¼ë“œë°± ê¸°ë¡ ì™„ë£Œ")
        
        # í•™ìŠµëœ ì œì•ˆ ì¡°íšŒ
        suggestions = await learning_processor.get_learned_suggestions(
            "ì•± ë°°í¬í•´ì¤˜",
            "test-user-123",
            {"project_name": "test-project"}
        )
        print(f"  í•™ìŠµëœ ì œì•ˆ: {len(suggestions)}ê°œ")
        
        print("\nâœ… ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"\nâŒ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


async def test_gemini_integration():
    """Gemini í†µí•© í…ŒìŠ¤íŠ¸ (ì‹¤ì œ API í‚¤ í•„ìš”)"""
    print("\n=== Gemini í†µí•© í…ŒìŠ¤íŠ¸ ===")
    
    # ì‹¤ì œ API í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âš ï¸  GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
        return
    
    try:
        # Gemini í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸
        from app.llm.multi_model_processor import GeminiClient, ModelType
        
        client = GeminiClient(
            ModelType.GEMINI,
            "https://generativelanguage.googleapis.com",
            api_key
        )
        
        # ê°„ë‹¨í•œ ëª…ë ¹ í…ŒìŠ¤íŠ¸
        context = {
            "project_name": "test-project",
            "current_deployments": []
        }
        
        print("Gemini API í˜¸ì¶œ ì¤‘...")
        response = await client.process_command("ì•ˆë…•í•˜ì„¸ìš”", context)
        
        print(f"  ì‘ë‹µ: {response.content[:100]}...")
        print(f"  ì‹ ë¢°ë„: {response.confidence:.2f}")
        print(f"  ì²˜ë¦¬ ì‹œê°„: {response.processing_time:.2f}ì´ˆ")
        
        await client.close()
        print("âœ… Gemini í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ Gemini í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


async def test_advanced_nlp_service():
    """ê³ ê¸‰ NLP ì„œë¹„ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\n=== ê³ ê¸‰ NLP ì„œë¹„ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸ ===")
    
    try:
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        service = AdvancedNLPService()
        await service.initialize()
        
        # í…ŒìŠ¤íŠ¸ ëª…ë ¹
        test_command = "web-appì„ stagingì— ë°°í¬í•´ì¤˜"
        context = {
            "project_name": "test-project",
            "current_deployments": [
                {"name": "web-app", "environment": "staging"}
            ]
        }
        
        print(f"ëª…ë ¹ ì²˜ë¦¬ ì¤‘: {test_command}")
        
        # ëª…ë ¹ ì²˜ë¦¬ (ì‹¤ì œ API í˜¸ì¶œ ì—†ì´)
        result = await service.process_command(
            user_id="test-user-123",
            project_name="test-project",
            command=test_command,
            context=context
        )
        
        print(f"  ì›ë³¸ ëª…ë ¹: {result['original_command']}")
        print(f"  í•´ì„ëœ ëª…ë ¹: {result['interpreted_command']}")
        print(f"  ì‹ ë¢°ë„: {result['confidence']:.2f}")
        print(f"  í’ˆì§ˆ: {result['quality']}")
        print(f"  ì‚¬ìš©ëœ ëª¨ë¸: {result['best_model']}")
        print(f"  ëª¨í˜¸í•¨: {len(result['ambiguities'])}ê°œ")
        print(f"  ì œì•ˆ: {len(result['suggestions'])}ê°œ")
        print(f"  í•™ìŠµëœ ì œì•ˆ: {len(result['learned_suggestions'])}ê°œ")
        
        await service.close()
        print("âœ… ê³ ê¸‰ NLP ì„œë¹„ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ê³ ê¸‰ NLP ì„œë¹„ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ê³ ê¸‰ NLP ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    await test_basic_functionality()
    
    # Gemini í†µí•© í…ŒìŠ¤íŠ¸ (ì„ íƒì )
    await test_gemini_integration()
    
    # ê³ ê¸‰ NLP ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    await test_advanced_nlp_service()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(main())





