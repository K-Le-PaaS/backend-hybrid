# NLP ì‹¤í–‰ ì•„í‚¤í…ì²˜

> **ëª©ì **: NLP ì‹œìŠ¤í…œì˜ ì „ì²´ ì•„í‚¤í…ì²˜ì™€ ì‹¤í–‰ íë¦„ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ëŠ” ë¬¸ì„œ

---

## ğŸ“‹ ëª©ì°¨
1. [ì‹œìŠ¤í…œ ê°œìš”](#ì‹œìŠ¤í…œ-ê°œìš”)
2. [ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨](#ì•„í‚¤í…ì²˜-ë‹¤ì´ì–´ê·¸ë¨)
3. [í•µì‹¬ ì»´í¬ë„ŒíŠ¸](#í•µì‹¬-ì»´í¬ë„ŒíŠ¸)
4. [ì‹¤í–‰ íë¦„](#ì‹¤í–‰-íë¦„)
5. [ë°ì´í„° ëª¨ë¸](#ë°ì´í„°-ëª¨ë¸)
6. [ì—ëŸ¬ ì²˜ë¦¬](#ì—ëŸ¬-ì²˜ë¦¬)
7. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
8. [ë³´ì•ˆ ê³ ë ¤ì‚¬í•­](#ë³´ì•ˆ-ê³ ë ¤ì‚¬í•­)

---

## ğŸ¯ ì‹œìŠ¤í…œ ê°œìš”

### **NLP Kubernetes ê´€ë¦¬ ì‹œìŠ¤í…œ**
K-Le-PaaSì˜ NLP ì‹œìŠ¤í…œì€ ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹ì„ Kubernetes í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ì‘ì—…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì§€ëŠ¥í˜• ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### **ì£¼ìš” íŠ¹ì§•**
- **ìì—°ì–´ ì´í•´**: Gemini LLMì„ í™œìš©í•œ ê³ ë„í™”ëœ ìì—°ì–´ ì²˜ë¦¬
- **14ê°€ì§€ ëª…ë ¹ì–´**: í¬ê´„ì ì¸ Kubernetes ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ë¹ ë¥¸ ì‘ë‹µê³¼ ì‹¤ì‹œê°„ ìƒíƒœ ì¡°íšŒ
- **ì—ëŸ¬ ë³µêµ¬**: ìƒì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€ì™€ ë³µêµ¬ ê°€ì´ë“œ
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ ëª…ë ¹ì–´ ì¶”ê°€ ìš©ì´

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TB
    subgraph "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤"
        UI[ì›¹ UI / Slack / API]
    end
    
    subgraph "NLP ì²˜ë¦¬ ê³„ì¸µ"
        API[FastAPI ì—”ë“œí¬ì¸íŠ¸<br/>/api/v1/nlp/process]
        NLP[NLP ì²˜ë¦¬ê¸°<br/>nlp.py]
        GEMINI[Gemini LLM<br/>gemini.py]
    end
    
    subgraph "ëª…ë ¹ì–´ ì²˜ë¦¬ ê³„ì¸µ"
        PLAN[ëª…ë ¹ ê³„íš<br/>commands.py]
        EXEC[ëª…ë ¹ ì‹¤í–‰<br/>commands.py]
    end
    
    subgraph "Kubernetes í´ë¼ì´ì–¸íŠ¸"
        K8S_CLIENT[K8s í´ë¼ì´ì–¸íŠ¸<br/>k8s_client.py]
        APPS[Apps V1 API<br/>Deployment ê´€ë¦¬]
        CORE[Core V1 API<br/>Pod, Service ê´€ë¦¬]
        NET[Networking V1 API<br/>Ingress ê´€ë¦¬]
    end
    
    subgraph "Kubernetes í´ëŸ¬ìŠ¤í„°"
        K8S[Kubernetes API Server]
        DEPLOY[Deployments]
        PODS[Pods]
        SVC[Services]
        ING[Ingresses]
    end
    
    UI --> API
    API --> NLP
    NLP --> GEMINI
    GEMINI --> PLAN
    PLAN --> EXEC
    EXEC --> K8S_CLIENT
    K8S_CLIENT --> APPS
    K8S_CLIENT --> CORE
    K8S_CLIENT --> NET
    APPS --> K8S
    CORE --> K8S
    NET --> K8S
    K8S --> DEPLOY
    K8S --> PODS
    K8S --> SVC
    K8S --> ING
```

---

## ğŸ”§ í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### **1. API ì—”ë“œí¬ì¸íŠ¸ (`app/api/v1/nlp.py`)**

#### **ì—­í• **
- ì‚¬ìš©ì ìš”ì²­ ìˆ˜ì‹  ë° ê²€ì¦
- NLP ì²˜ë¦¬ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- ì‘ë‹µ í¬ë§·íŒ… ë° ë°˜í™˜

#### **ì£¼ìš” ê¸°ëŠ¥**
```python
@router.post("/process")
async def process_nlp_command(request: NLPRequest):
    # 1. ì…ë ¥ ê²€ì¦
    validate_command(request.command)
    
    # 2. NLP ì²˜ë¦¬
    result = await nlp_service.process(request)
    
    # 3. ì‘ë‹µ ë°˜í™˜
    return NLPResponse(
        success=True,
        data=result
    )
```

### **2. Gemini LLM í´ë¼ì´ì–¸íŠ¸ (`app/llm/gemini.py`)**

#### **ì—­í• **
- ìì—°ì–´ ëª…ë ¹ í•´ì„
- êµ¬ì¡°í™”ëœ JSON ë³€í™˜
- 14ê°€ì§€ ëª…ë ¹ì–´ íŒ¨í„´ ì¸ì‹

#### **ì£¼ìš” ê¸°ëŠ¥**
```python
class GeminiClient:
    async def interpret(self, command: str) -> Dict[str, Any]:
        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = self._build_system_prompt()
        
        # 2. Gemini API í˜¸ì¶œ
        response = await self._call_gemini_api(command, system_prompt)
        
        # 3. JSON íŒŒì‹± ë° ê²€ì¦
        return self._parse_response(response)
```

### **3. ëª…ë ¹ì–´ ì²˜ë¦¬ê¸° (`app/services/commands.py`)**

#### **ì—­í• **
- ëª…ë ¹ì–´ ê³„íš ìˆ˜ë¦½
- Kubernetes API í˜¸ì¶œ
- ê²°ê³¼ ë°ì´í„° ê°€ê³µ

#### **ì£¼ìš” ê¸°ëŠ¥**
```python
def plan_command(req: CommandRequest) -> CommandPlan:
    # ëª…ë ¹ì–´ë³„ ì‹¤í–‰ ê³„íš ìƒì„±
    
async def execute_command(plan: CommandPlan) -> Dict[str, Any]:
    # ì‹¤ì œ Kubernetes ì‘ì—… ì‹¤í–‰
```

### **4. Kubernetes í´ë¼ì´ì–¸íŠ¸ (`app/services/k8s_client.py`)**

#### **ì—­í• **
- Kubernetes API í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬
- ì—°ê²° ì„¤ì • ë° ì¸ì¦
- API í˜¸ì¶œ ìµœì í™”

#### **ì£¼ìš” ê¸°ëŠ¥**
```python
def get_core_v1_api(context: Optional[str] = None) -> client.CoreV1Api:
    # Core V1 API í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜

def get_apps_v1_api(context: Optional[str] = None) -> client.AppsV1Api:
    # Apps V1 API í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜

def get_networking_v1_api(context: Optional[str] = None) -> client.NetworkingV1Api:
    # Networking V1 API í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜
```

---

## ğŸ”„ ì‹¤í–‰ íë¦„

### **1. ìš”ì²­ ìˆ˜ì‹  ë‹¨ê³„**
```python
# ì‚¬ìš©ì ìì—°ì–´ ì…ë ¥
command = "nginx ìƒíƒœ í™•ì¸í•´ì¤˜"

# API ìš”ì²­ êµ¬ì„±
request = NLPRequest(
    command=command,
    timestamp="2025-10-13T11:20:00Z",
    context={"project_name": "test"}
)
```

### **2. NLP ì²˜ë¦¬ ë‹¨ê³„**
```python
# Gemini LLM í•´ì„
interpretation = await gemini_client.interpret(command)
# ê²°ê³¼: {"command": "status", "parameters": {"appName": "nginx", "namespace": "default"}}

# CommandRequest ìƒì„±
command_req = CommandRequest(
    command="status",
    app_name="nginx",
    namespace="default",
    replicas=1,
    lines=30,
    version="",
    previous=False
)
```

### **3. ëª…ë ¹ ê³„íš ë‹¨ê³„**
```python
# ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
plan = plan_command(command_req)
# ê²°ê³¼: CommandPlan(tool="k8s_get_status", args={"name": "nginx", "namespace": "default"})
```

### **4. Kubernetes ì‹¤í–‰ ë‹¨ê³„**
```python
# Kubernetes API í˜¸ì¶œ
result = await execute_command(plan)

# Apps V1 APIë¡œ Deployment ì¡°íšŒ
apps_v1 = get_apps_v1_api()
deployment = apps_v1.read_namespaced_deployment(name="nginx", namespace="default")

# Core V1 APIë¡œ Pod ì¡°íšŒ
core_v1 = get_core_v1_api()
pods = core_v1.list_namespaced_pod(namespace="default", label_selector="app=nginx")
```

### **5. ì‘ë‹µ êµ¬ì„± ë‹¨ê³„**
```python
# ê²°ê³¼ ë°ì´í„° ê°€ê³µ
response_data = {
    "status": "success",
    "deployment": {
        "name": "nginx",
        "replicas": {"desired": 1, "current": 1, "ready": 1, "available": 1},
        "image": "nginx:1.21",
        "status": "Running"
    },
    "pods": [
        {
            "name": "nginx-xxx-1",
            "phase": "Running",
            "ready": "1/1",
            "restarts": 0
        }
    ]
}

# ìµœì¢… ì‘ë‹µ ë°˜í™˜
return NLPResponse(
    success=True,
    message="ëª…ë ¹ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
    data=response_data
)
```

---

## ğŸ“Š ë°ì´í„° ëª¨ë¸

### **1. ì…ë ¥ ë°ì´í„° ëª¨ë¸**
```python
class NLPRequest(BaseModel):
    command: str = Field(min_length=1, max_length=1000)
    timestamp: str
    context: Dict[str, Any] = Field(default_factory=dict)
```

### **2. ì¤‘ê°„ ë°ì´í„° ëª¨ë¸**
```python
class CommandRequest(BaseModel):
    command: str = Field(min_length=1)
    app_name: str = Field(default="")
    replicas: int = Field(default=1)
    lines: int = Field(default=30, ge=1, le=100)
    version: str = Field(default="")
    namespace: str = Field(default="default")
    previous: bool = Field(default=False)

@dataclass
class CommandPlan:
    tool: str
    args: Dict[str, Any]
```

### **3. ì¶œë ¥ ë°ì´í„° ëª¨ë¸**
```python
class NLPResponse(BaseModel):
    success: bool
    message: str
    data: Dict[str, Any] = Field(default_factory=dict)
    error: Optional[str] = None
```

---

## âš ï¸ ì—ëŸ¬ ì²˜ë¦¬

### **1. ì…ë ¥ ê²€ì¦ ì—ëŸ¬**
```python
# ëª…ë ¹ì–´ ê¸¸ì´ ì´ˆê³¼
if len(command) > 1000:
    raise HTTPException(status_code=400, detail="ëª…ë ¹ì–´ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤.")

# ë¡œê·¸ ì¤„ ìˆ˜ ì´ˆê³¼
if req.lines > 100:
    raise HTTPException(status_code=400, detail="ë¡œê·¸ ì¤„ ìˆ˜ëŠ” ìµœëŒ€ 100ì¤„ê¹Œì§€ ì¡°íšŒ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
```

### **2. Gemini API ì—ëŸ¬**
```python
try:
    response = await gemini_client.interpret(command)
except Exception as e:
    return {
        "success": False,
        "error": f"ìì—°ì–´ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
    }
```

### **3. Kubernetes API ì—ëŸ¬**
```python
try:
    deployment = apps_v1.read_namespaced_deployment(name=name, namespace=namespace)
except ApiException as e:
    if e.status == 404:
        return {
            "status": "error",
            "message": f"Deployment '{name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }
    return {
        "status": "error",
        "message": f"Kubernetes API ì˜¤ë¥˜: {e.reason}"
    }
```

---

## ğŸš€ ì„±ëŠ¥ ìµœì í™”

### **1. API í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©**
```python
# ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ API í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©
@lru_cache(maxsize=1)
def get_apps_v1_api() -> client.AppsV1Api:
    return client.AppsV1Api()
```

### **2. ë³‘ë ¬ ì²˜ë¦¬**
```python
# ì—¬ëŸ¬ ë¦¬ì†ŒìŠ¤ ë™ì‹œ ì¡°íšŒ
async def get_overview_data(namespace: str):
    apps_v1 = get_apps_v1_api()
    core_v1 = get_core_v1_api()
    networking_v1 = get_networking_v1_api()
    
    # ë³‘ë ¬ë¡œ ë¦¬ì†ŒìŠ¤ ì¡°íšŒ
    deployments_task = asyncio.create_task(get_deployments(apps_v1, namespace))
    pods_task = asyncio.create_task(get_pods(core_v1, namespace))
    services_task = asyncio.create_task(get_services(core_v1, namespace))
    ingresses_task = asyncio.create_task(get_ingresses(networking_v1, namespace))
    
    # ëª¨ë“  ê²°ê³¼ ëŒ€ê¸°
    deployments, pods, services, ingresses = await asyncio.gather(
        deployments_task, pods_task, services_task, ingresses_task
    )
```

### **3. ìºì‹± ì „ëµ**
```python
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ëª©ë¡ ìºì‹± (5ë¶„)
@cache(ttl=300)
async def get_namespace_list():
    core_v1 = get_core_v1_api()
    return core_v1.list_namespace()
```

---

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### **1. ì…ë ¥ ê²€ì¦**
```python
# ìœ„í—˜í•œ ëª…ë ¹ì–´ ì°¨ë‹¨
dangerous_keywords = ["rm", "delete", "kill", "shutdown"]
if any(keyword in command.lower() for keyword in dangerous_keywords):
    raise HTTPException(status_code=400, detail="ìœ„í—˜í•œ ëª…ë ¹ì–´ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
```

### **2. Kubernetes RBAC**
```python
# í•„ìš”í•œ ìµœì†Œ ê¶Œí•œë§Œ ë¶€ì—¬
# - get, list: ì¡°íšŒ ëª…ë ¹ì–´
# - patch: restart, scale ëª…ë ¹ì–´
# - create: deploy ëª…ë ¹ì–´
```

### **3. API í‚¤ ë³´ì•ˆ**
```python
# Gemini API í‚¤ í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
```

---

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### **1. êµ¬ì¡°í™”ëœ ë¡œê¹…**
```python
import structlog

logger = structlog.get_logger()

# ëª…ë ¹ì–´ ì‹¤í–‰ ë¡œê¹…
logger.info(
    "command_executed",
    command=req.command,
    app_name=req.app_name,
    namespace=req.namespace,
    execution_time=execution_time
)
```

### **2. ë©”íŠ¸ë¦­ ìˆ˜ì§‘**
```python
# Prometheus ë©”íŠ¸ë¦­
from prometheus_client import Counter, Histogram

command_counter = Counter('nlp_commands_total', 'Total NLP commands', ['command', 'status'])
command_duration = Histogram('nlp_command_duration_seconds', 'Command execution time', ['command'])
```

---

## ğŸ”„ ì—…ë°ì´íŠ¸ ì´ë ¥

| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ì‚¬í•­ |
|------|------|----------|
| 1.0.0 | 2025-10-12 | ì´ˆê¸° ì•„í‚¤í…ì²˜ ë¬¸ì„œ ì‘ì„± |
| 2.0.0 | 2025-10-13 | 14ê°œ ëª…ë ¹ì–´ ì•„í‚¤í…ì²˜ë¡œ í™•ì¥, ì½”ë“œë¦¬ë·° ë°˜ì˜ |

---

**ì‘ì„±ì**: AI Assistant  
**ìµœì¢… ìˆ˜ì •**: 2025-10-13  
**ë‹¤ìŒ ì—…ë°ì´íŠ¸**: ìƒˆë¡œìš´ ì»´í¬ë„ŒíŠ¸ ì¶”ê°€ ì‹œ